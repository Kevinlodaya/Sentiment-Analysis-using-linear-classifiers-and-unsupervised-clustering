{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHiCLxb+YnMiSRTU1WBihz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevinlodaya/Sentiment-Analysis-using-linear-classifiers-and-unsupervised-clustering/blob/main/Linear_%26_Classification_Methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required packages"
      ],
      "metadata": {
        "id": "Ed7kpEtsEVMN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CsCki1qSC4Q3"
      },
      "outputs": [],
      "source": [
        "# Importing standard libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import math\n",
        "import random\n",
        "\n",
        "# Importing linear classification algorithms\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Importing the clustering algorithms\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Importing preprocessing functions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Importing metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# Suppressing warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How does the dataset look like?\n",
        "Lets use a standard dataset from Amazon which contains reviews and ratings from the customer. The original dataset has three features: name(name of the products), review(Customer reviews of the products), and rating(rating of the customer of a product ranging from 1 to 5). The review column will be the input column and the rating column will be used to understand the sentiments of the review. Here are some important data preprocessing steps:\n",
        "The dataset has about 183,500 rows of data. There are 1147 null values which will be removed.\n",
        "As the dataset is pretty big, it takes a lot of time to run some machine learning algorithms. We will use 30% of the data in this project which is still 54,000+ data points! The sample will be representative of the whole dataset.\n",
        "If the rating is 1 and 2 that will be considered a negative review. And if the review is 3, 4, and 5, the review will be considered as a  positive review. We add a new column named ‘sentiments’ to the dataset that will use 1 for the positive reviews and 0 for the negative reviews. We read and display the contents of the dataset down below."
      ],
      "metadata": {
        "id": "GIxaECCFJC5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget #Add your dataset link/Url\n",
        "!unzip #Unzip the folder you have added on your life.\n",
        "data = pd.read_csv('amazon_reviews.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "koc4CyWhD6w3",
        "outputId": "6c30cbcd-a124-432c-db1c-c0bc7e2ae1be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-03 19:55:31--  https://cdn.iisc.talentsprint.com/ADSMI/Datasets/amazon_reviews.zip\n",
            "Resolving cdn.iisc.talentsprint.com (cdn.iisc.talentsprint.com)... 172.105.52.210\n",
            "Connecting to cdn.iisc.talentsprint.com (cdn.iisc.talentsprint.com)|172.105.52.210|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29949034 (29M) [application/zip]\n",
            "Saving to: ‘amazon_reviews.zip.2’\n",
            "\n",
            "amazon_reviews.zip. 100%[===================>]  28.56M  8.02MB/s    in 3.6s    \n",
            "\n",
            "2023-10-03 19:55:36 (8.02 MB/s) - ‘amazon_reviews.zip.2’ saved [29949034/29949034]\n",
            "\n",
            "Archive:  amazon_reviews.zip\n",
            "replace amazon_reviews.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: amazon_reviews.csv      \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                name  \\\n",
              "0                           Planetwise Flannel Wipes   \n",
              "1                              Planetwise Wipe Pouch   \n",
              "2                Annas Dream Full Quilt with 2 Shams   \n",
              "3  Stop Pacifier Sucking without tears with Thumb...   \n",
              "4  Stop Pacifier Sucking without tears with Thumb...   \n",
              "\n",
              "                                              review  rating  \n",
              "0  These flannel wipes are OK, but in my opinion ...       3  \n",
              "1  it came early and was not disappointed. i love...       5  \n",
              "2  Very soft and comfortable and warmer than it l...       5  \n",
              "3  This is a product well worth the purchase.  I ...       5  \n",
              "4  All of my kids have cried non-stop when I trie...       5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aeadf17b-dba2-4d73-ae6d-e3932a474ce4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Planetwise Flannel Wipes</td>\n",
              "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Planetwise Wipe Pouch</td>\n",
              "      <td>it came early and was not disappointed. i love...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
              "      <td>Very soft and comfortable and warmer than it l...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
              "      <td>This is a product well worth the purchase.  I ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
              "      <td>All of my kids have cried non-stop when I trie...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aeadf17b-dba2-4d73-ae6d-e3932a474ce4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aeadf17b-dba2-4d73-ae6d-e3932a474ce4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aeadf17b-dba2-4d73-ae6d-e3932a474ce4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f869bfc-1734-4c16-9f3c-08b74ddf84a5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f869bfc-1734-4c16-9f3c-08b74ddf84a5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f869bfc-1734-4c16-9f3c-08b74ddf84a5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis and Preprocessing"
      ],
      "metadata": {
        "id": "-JnhzBpOEY3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of rows and columns\n",
        "num_rows, num_columns = data.shape\n",
        "print(f\"Number of rows: {num_rows}\")\n",
        "print(f\"Number of columns: {num_columns}\")\n",
        "\n",
        "# Summary of the dataset\n",
        "data.info()\n",
        "\n",
        "# Statistical description of the features\n",
        "print(data.describe())\n",
        "\n",
        "# Check for duplicate values\n",
        "duplicates = data.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {duplicates}\")\n",
        "\n",
        "# Show the top 5 and the last 5 rows of the data\n",
        "print(\"Top 5 rows:\")\n",
        "print(data.head())\n",
        "print(\"\\nLast 5 rows:\")\n",
        "print(data.tail())\n",
        "print('Unique Ratings:', sorted(list(data['rating'].unique())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u1p-8AuEeW-",
        "outputId": "6ec49403-f14f-4361-e5b8-8e9a4f747bee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 183531\n",
            "Number of columns: 3\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 183531 entries, 0 to 183530\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   name    183213 non-null  object\n",
            " 1   review  182702 non-null  object\n",
            " 2   rating  183531 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 4.2+ MB\n",
            "              rating\n",
            "count  183531.000000\n",
            "mean        4.120448\n",
            "std         1.285017\n",
            "min         1.000000\n",
            "25%         4.000000\n",
            "50%         5.000000\n",
            "75%         5.000000\n",
            "max         5.000000\n",
            "Number of duplicate rows: 62\n",
            "Top 5 rows:\n",
            "                                                name  \\\n",
            "0                           Planetwise Flannel Wipes   \n",
            "1                              Planetwise Wipe Pouch   \n",
            "2                Annas Dream Full Quilt with 2 Shams   \n",
            "3  Stop Pacifier Sucking without tears with Thumb...   \n",
            "4  Stop Pacifier Sucking without tears with Thumb...   \n",
            "\n",
            "                                              review  rating  \n",
            "0  These flannel wipes are OK, but in my opinion ...       3  \n",
            "1  it came early and was not disappointed. i love...       5  \n",
            "2  Very soft and comfortable and warmer than it l...       5  \n",
            "3  This is a product well worth the purchase.  I ...       5  \n",
            "4  All of my kids have cried non-stop when I trie...       5  \n",
            "\n",
            "Last 5 rows:\n",
            "                                                     name  \\\n",
            "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
            "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
            "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
            "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
            "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
            "\n",
            "                                                   review  rating  \n",
            "183526  Such a great idea! very handy to have and look...       5  \n",
            "183527  This product rocks!  It is a great blend of fu...       5  \n",
            "183528  This item looks great and cool for my kids.......       5  \n",
            "183529  I am extremely happy with this product. I have...       5  \n",
            "183530  I love this product very mush . I have bought ...       5  \n",
            "Unique Ratings: [1, 2, 3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preprocessing\n",
        "# Check for null values\n",
        "null_values = data.isnull().sum()\n",
        "print(\"Null values per column:\")\n",
        "print(null_values)\n",
        "\n",
        "# Handle null values (if any)\n",
        "data = data.dropna()  # Remove rows with null values\n",
        "\n",
        "# Create a new column 'sentiments' based on the 'rating' column\n",
        "data['sentiments'] = data['rating'].apply(lambda x: 1 if x >= 3 else 0)\n",
        "\n",
        "# Display the first few rows after preprocessing\n",
        "print(\"\\nData after preprocessing:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugVP1veDEgcL",
        "outputId": "e9dc988f-f40b-4b50-de7c-7a0f6f0ac09c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null values per column:\n",
            "name      318\n",
            "review    829\n",
            "rating      0\n",
            "dtype: int64\n",
            "\n",
            "Data after preprocessing:\n",
            "                                                name  \\\n",
            "0                           Planetwise Flannel Wipes   \n",
            "1                              Planetwise Wipe Pouch   \n",
            "2                Annas Dream Full Quilt with 2 Shams   \n",
            "3  Stop Pacifier Sucking without tears with Thumb...   \n",
            "4  Stop Pacifier Sucking without tears with Thumb...   \n",
            "\n",
            "                                              review  rating  sentiments  \n",
            "0  These flannel wipes are OK, but in my opinion ...       3           1  \n",
            "1  it came early and was not disappointed. i love...       5           1  \n",
            "2  Very soft and comfortable and warmer than it l...       5           1  \n",
            "3  This is a product well worth the purchase.  I ...       5           1  \n",
            "4  All of my kids have cried non-stop when I trie...       5           1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split train and test data"
      ],
      "metadata": {
        "id": "YuMs2IrmEpE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features (reviews) and target (sentiments)\n",
        "X = data['review']\n",
        "y = data['sentiments']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train = X_train[:5000]\n",
        "y_train = y_train[:5000]\n",
        "X_test = X_test[:500]\n",
        "y_test = y_test[:500]\n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
        "\n",
        "# Tokenize and vectorize the text data (you may need to install a text vectorization library)\n",
        "# Example using TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust max_features as needed\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "print(X_train_tfidf.shape,X_test_tfidf.shape)\n",
        "print('Training value')\n",
        "print(y_train.value_counts())\n",
        "print('Test value')\n",
        "print(y_test.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU6NrWEQEqst",
        "outputId": "a7160f21-5273-4de6-9d22-62e827b360ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000,) (500,) (5000,) (500,)\n",
            "(5000, 5000) (500, 5000)\n",
            "Training value\n",
            "1    4276\n",
            "0     724\n",
            "Name: sentiments, dtype: int64\n",
            "Test value\n",
            "1    415\n",
            "0     85\n",
            "Name: sentiments, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation using K-Nearest Neighbor (KNN) Classifier"
      ],
      "metadata": {
        "id": "pamYU5HoEvKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the KNN classifier\n",
        "k = 5\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Train the KNN classifier on the training data\n",
        "knn_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = knn_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "#Generate a classification report for Train data\n",
        "y_train_pred = knn_classifier.predict(X_train_tfidf)\n",
        "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
        "report_train = classification_report(y_train, y_train_pred)\n",
        "\n",
        "print(f\"Accuracy on Training Data: {accuracy_train}\")\n",
        "print(\"Classification Report:\\n\", report_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0bgTYF6ExlA",
        "outputId": "114e8cb2-1cff-4f27-c50d-c5e461f9eae2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.83\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.02      0.04        85\n",
            "           1       0.83      1.00      0.91       415\n",
            "\n",
            "    accuracy                           0.83       500\n",
            "   macro avg       0.67      0.51      0.48       500\n",
            "weighted avg       0.78      0.83      0.76       500\n",
            "\n",
            "Accuracy on Training Data: 0.8656\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.07      0.13       724\n",
            "           1       0.86      1.00      0.93      4276\n",
            "\n",
            "    accuracy                           0.87      5000\n",
            "   macro avg       0.93      0.54      0.53      5000\n",
            "weighted avg       0.88      0.87      0.81      5000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation using Support Vector Machines (SVM) Classifier:"
      ],
      "metadata": {
        "id": "0ZYjiVwMFT_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementation using Support Vector Machines (SVM) Classifier**:  (3 points)\n",
        "  - First Reduce the features using PCA\n",
        "  - use Hard-Margin Classifier\n",
        "  - use Soft-Margin Classifier\n",
        "  - use Kernel SVM Classifier\n",
        "\n",
        "\n",
        "\n",
        "Background:\n",
        "The next classifier we look into are support vector machines.\n",
        "\n",
        "![wget](https://cdn.talentsprint.com/aiml/aiml_2020_b14_hyd/experiment_details_backup/linear_data.png)\n",
        "\n",
        "While the other classifiers such as the perceptron and the logistic regression uses a similar concept of finding a boundary between two classes using a straight line, SVMs aim to maximize this boundary. Therefore, not only the SVM tries to find a boundary, it tries to find the best boundary that separates the two classes. Again, with very simple tricks the two class classification can be easily extended to a multiclass classification. The formal formulation of a SVM is,\n",
        "\n",
        "$g(x) = w^Tx + b$, is the equation of the line we want to find with weights $w$ and a bias $b$.\n",
        "\n",
        "Now as seen from the figure, $g(x) = k$ and $g(x) = -k$ will give two worst lines for classification as they are right at the boundary of one of the classes. We need to maximize the distance of the line from both of the classes.\n",
        "\n",
        "Therefore,\n",
        "\n",
        "Maximize $k$ such that :\n",
        "\n",
        "$-w^Tx + b \\geq k \\: for \\: d_i == 1$\n",
        "\n",
        "$-w^Tx + b \\leq k \\: for \\: d_i == -1$\n",
        "\n",
        "We keep $g(x) \\geq 1$ and minimize $||w||$.\n",
        "\n",
        "We finally write the final minimization function (uses Lagrangians to come to this solution).\n",
        "\n",
        "Minimize: $J(w, b, \\alpha) = \\frac{1}{2}w^Tw - \\Sigma_{i=1}^{N}(\\alpha_id_i(w^Tx_i + b)) + \\Sigma_{i=1}^{N}(\\alpha_i)$\n",
        "\n",
        "There are multiple types of SVM. We first use the standard linear SVM and check the performance of the model. However, SVM cannot be directly used on this dataset.   "
      ],
      "metadata": {
        "id": "cUeC_iK9IV38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is too large and the normal SVM function from `sklearn` will take a lot of time to run. Therefore, we first apply a PCA based dimensionality reduction technique on the input data. This will be followed by different types of SVM techniques and the performance can be compared. Since, dimensionality reduction is applied, a slight drop in performance is expected. However, with the improvement in the time taken for training a SVM in mind, it is important we first apply PCA based dimensionality reduction.\n",
        "\n",
        "In principal component analysis, this relationship is quantified by finding a list of the principal axes in the data, and using those axes to describe the dataset.Using PCA for dimensionality reduction involves zeroing out one or more of the smallest principal components, resulting in a lower-dimensional projection of the data that preserves the maximal data variance.\n",
        "\n",
        "\n",
        "**Hints**\n",
        "- Define the PCA model using sklearn's **TruncatedSVD**\n",
        "- Fit the training data using **model.fit**\n",
        "- Reduce the dimensions of the training data using **model.transform**\n",
        "- Reduce the dimensions of the testing data using **model.transform**\n",
        "\n",
        "\n",
        "- Use sklearn's **svm.SVC**. Appropriately choose the arguments - *kernel*, *gamma*, and *C* for hard-margin, soft-margin and kernel SVM classifiers.\n",
        "\n"
      ],
      "metadata": {
        "id": "t8kRogCMIXQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the number of PCA components\n",
        "n_components = 100\n",
        "pca = PCA(n_components=n_components)\n",
        "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
        "X_test_pca = pca.transform(X_test_tfidf.toarray())\n",
        "\n",
        "# Optimize SVM parameters\n",
        "# 1. Hard-Margin Classifier\n",
        "hard_margin_classifier = SVC(kernel='linear', C=10.0)  # Adjust C as needed for faster convergence\n",
        "\n",
        "# Train the hard-margin SVM classifier on the training data\n",
        "hard_margin_classifier.fit(X_train_pca, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_hard_margin = hard_margin_classifier.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the hard-margin SVM classifier\n",
        "accuracy_hard_margin = accuracy_score(y_test, y_pred_hard_margin)\n",
        "print(\"Hard-Margin SVM Classifier:\")\n",
        "print(f\"Accuracy: {accuracy_hard_margin}\")\n",
        "report_hard_margin = classification_report(y_test, y_pred_hard_margin)\n",
        "print(\"Classification Report:\\n\", report_hard_margin)\n",
        "\n",
        "# 2. Soft-Margin Classifier\n",
        "soft_margin_classifier = SVC(kernel='linear', C=1.0)  # Adjust C as needed for faster convergence\n",
        "\n",
        "# Train the soft-margin SVM classifier on the training data\n",
        "soft_margin_classifier.fit(X_train_pca, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_soft_margin = soft_margin_classifier.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the soft-margin SVM classifier\n",
        "accuracy_soft_margin = accuracy_score(y_test, y_pred_soft_margin)\n",
        "print(\"\\nSoft-Margin SVM Classifier:\")\n",
        "print(f\"Accuracy: {accuracy_soft_margin}\")\n",
        "report_soft_margin = classification_report(y_test, y_pred_soft_margin)\n",
        "print(\"Classification Report:\\n\", report_soft_margin)\n",
        "\n",
        "# 3. Kernel SVM Classifier (RBF Kernel)\n",
        "kernel_svm_classifier = SVC(kernel='rbf', C=1.0)  # Adjust kernel and C as needed for faster convergence\n",
        "\n",
        "# Train the kernel SVM classifier on the training data\n",
        "kernel_svm_classifier.fit(X_train_pca, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_kernel_svm = kernel_svm_classifier.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the kernel SVM classifier\n",
        "accuracy_kernel_svm = accuracy_score(y_test, y_pred_kernel_svm)\n",
        "print(\"\\nKernel SVM Classifier:\")\n",
        "print(f\"Accuracy: {accuracy_kernel_svm}\")\n",
        "report_kernel_svm = classification_report(y_test, y_pred_kernel_svm)\n",
        "print(\"Classification Report:\\n\", report_kernel_svm)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOuJBoILFWLq",
        "outputId": "ddf11a43-f78d-4c24-a496-7bea10f734a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hard-Margin SVM Classifier:\n",
            "Accuracy: 0.85\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.14      0.24        85\n",
            "           1       0.85      1.00      0.92       415\n",
            "\n",
            "    accuracy                           0.85       500\n",
            "   macro avg       0.85      0.57      0.58       500\n",
            "weighted avg       0.85      0.85      0.80       500\n",
            "\n",
            "\n",
            "Soft-Margin SVM Classifier:\n",
            "Accuracy: 0.83\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        85\n",
            "           1       0.83      1.00      0.91       415\n",
            "\n",
            "    accuracy                           0.83       500\n",
            "   macro avg       0.41      0.50      0.45       500\n",
            "weighted avg       0.69      0.83      0.75       500\n",
            "\n",
            "\n",
            "Kernel SVM Classifier:\n",
            "Accuracy: 0.848\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.13      0.22        85\n",
            "           1       0.85      1.00      0.92       415\n",
            "\n",
            "    accuracy                           0.85       500\n",
            "   macro avg       0.85      0.56      0.57       500\n",
            "weighted avg       0.85      0.85      0.80       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the accuracy for each classifier on the training data\n",
        "train_accuracy_hard_margin = hard_margin_classifier.score(X_train_pca, y_train)\n",
        "train_accuracy_soft_margin = soft_margin_classifier.score(X_train_pca, y_train)\n",
        "train_accuracy_kernel_svm = kernel_svm_classifier.score(X_train_pca, y_train)\n",
        "\n",
        "print(\"\\nTraining Data Accuracy:\")\n",
        "print(f\"Hard-Margin SVM Classifier: {train_accuracy_hard_margin}\")\n",
        "print(f\"Soft-Margin SVM Classifier: {train_accuracy_soft_margin}\")\n",
        "print(f\"Kernel SVM Classifier: {train_accuracy_kernel_svm}\")\n",
        "\n",
        "# Print the accuracy for each classifier on the test data\n",
        "print(\"\\nTest Data Accuracy:\")\n",
        "print(f\"Hard-Margin SVM Classifier: {accuracy_hard_margin}\")\n",
        "print(f\"Soft-Margin SVM Classifier: {accuracy_soft_margin}\")\n",
        "print(f\"Kernel SVM Classifier: {accuracy_kernel_svm}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxgnIFpMFb-j",
        "outputId": "a88bba92-8a51-42d7-96de-bb416e346b14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Data Accuracy:\n",
            "Hard-Margin SVM Classifier: 0.8826\n",
            "Soft-Margin SVM Classifier: 0.8552\n",
            "Kernel SVM Classifier: 0.9176\n",
            "\n",
            "Test Data Accuracy:\n",
            "Hard-Margin SVM Classifier: 0.85\n",
            "Soft-Margin SVM Classifier: 0.83\n",
            "Kernel SVM Classifier: 0.848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation using Decision Trees"
      ],
      "metadata": {
        "id": "TLPr8HuJFeXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   **Implementation using Decision Trees**:  (1 point)\n",
        "\n",
        "Decision Trees are supervised Machine Learning algorithms that can perform both classification and regression tasks and even multioutput tasks. They can handle complex datasets. As the name shows, it uses a tree-like model to make decisions in order to classify or predict according to the problem. It is an ML algorithm that progressively divides datasets into smaller data groups based on a descriptive feature until it reaches sets that are small enough to be described by some label.\n",
        "\n",
        "The most important part of a decision tree is its explainability!\n",
        "\n",
        "The importance of decision tree algorithm is that it has many applications in the real world. For example:\n",
        "\n",
        "1. In the Healthcare sector: To develop Clinical Decision Analysis tools which allow decision-makers to apply for evidence-based medicine and make objective clinical decisions when faced with complex situations.\n",
        "2. Virtual Assistants (Chatbots): To develop chatbots that provide information and assistance to customers in any required domain.\n",
        "3. Retail and Marketing: Sentiment analysis detects the pulse of customer feedback and emotions and allows organizations to learn about customer choices and drives decisions.\n",
        "\n",
        "**Hint**\n",
        "Use sklearn's **DecisionTreeClassifier** function"
      ],
      "metadata": {
        "id": "_-iQE2u1IeTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the Decision Tree classifier on the training data\n",
        "decision_tree_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the training data\n",
        "y_pred_train_decision_tree = decision_tree_classifier.predict(X_train_tfidf)\n",
        "\n",
        "# Calculate accuracy on the training data\n",
        "accuracy_train_decision_tree = accuracy_score(y_train, y_pred_train_decision_tree)\n",
        "print(\"Decision Tree Classifier (Training Data):\")\n",
        "print(f\"Accuracy: {accuracy_train_decision_tree}\")\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_test_decision_tree = decision_tree_classifier.predict(X_test_tfidf)\n",
        "\n",
        "# Calculate accuracy on the test data\n",
        "accuracy_test_decision_tree = accuracy_score(y_test, y_pred_test_decision_tree)\n",
        "print(\"\\nDecision Tree Classifier (Testing Data):\")\n",
        "print(f\"Accuracy: {accuracy_test_decision_tree}\")\n",
        "\n",
        "# Generate a classification report for the test data\n",
        "report_decision_tree = classification_report(y_test, y_pred_test_decision_tree)\n",
        "print(\"\\nClassification Report (Testing Data):\\n\", report_decision_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLEt1O1nFgPG",
        "outputId": "c1efbeaf-0c84-4188-c42d-79e928d36b23"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Classifier (Training Data):\n",
            "Accuracy: 1.0\n",
            "\n",
            "Decision Tree Classifier (Testing Data):\n",
            "Accuracy: 0.81\n",
            "\n",
            "Classification Report (Testing Data):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.41      0.42        85\n",
            "           1       0.88      0.89      0.89       415\n",
            "\n",
            "    accuracy                           0.81       500\n",
            "   macro avg       0.66      0.65      0.66       500\n",
            "weighted avg       0.81      0.81      0.81       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation using Ensemble Classifier:"
      ],
      "metadata": {
        "id": "vDduEhAdFjOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the number of PCA components\n",
        "n_components = 100\n",
        "pca = PCA(n_components=n_components)\n",
        "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
        "X_test_pca = pca.transform(X_test_tfidf.toarray())\n",
        "\n",
        "# Instantiate a MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Scale your data (replace X_train_pca and X_test_pca with your data)\n",
        "X_train_pca_scaled = scaler.fit_transform(X_train_pca)\n",
        "X_test_pca_scaled = scaler.transform(X_test_pca)\n",
        "\n",
        "# Define individual classifiers\n",
        "logistic_classifier = LogisticRegression()\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "svm_classifier = SVC(kernel='linear', C=1.0, probability=True)\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "\n",
        "# Create a Voting Classifier with 'soft' voting\n",
        "ensemble_classifier = VotingClassifier(estimators=[\n",
        "    ('logistic', logistic_classifier),\n",
        "    ('knn', knn_classifier),\n",
        "    ('svm', svm_classifier),\n",
        "    ('naive_bayes', naive_bayes_classifier)\n",
        "], voting='soft')\n",
        "\n",
        "# Train the ensemble classifier on the training data\n",
        "ensemble_classifier.fit(X_train_pca_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_ensemble = ensemble_classifier.predict(X_test_pca_scaled)\n",
        "\n",
        "# Evaluate the ensemble classifier\n",
        "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
        "print(\"Ensemble Classifier:\")\n",
        "print(f\"Accuracy: {accuracy_ensemble}\")\n",
        "report_ensemble = classification_report(y_test, y_pred_ensemble)\n",
        "print(\"Classification Report:\\n\", report_ensemble)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JamZTTaFm52",
        "outputId": "8fe57b84-c2ec-4df7-eec7-eea97dde74c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Classifier:\n",
            "Accuracy: 0.834\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.05      0.09        85\n",
            "           1       0.84      1.00      0.91       415\n",
            "\n",
            "    accuracy                           0.83       500\n",
            "   macro avg       0.75      0.52      0.50       500\n",
            "weighted avg       0.81      0.83      0.77       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the ensemble classifier on the training data\n",
        "train_accuracy_ensemble = ensemble_classifier.score(X_train_pca_scaled, y_train)\n",
        "train_report_ensemble = classification_report(y_train, ensemble_classifier.predict(X_train_pca_scaled))\n",
        "\n",
        "# Print the results\n",
        "print(\"Ensemble Classifier - Training Data:\")\n",
        "print(f\"Accuracy: {train_accuracy_ensemble}\")\n",
        "print(\"Classification Report:\\n\", train_report_ensemble)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j76CRdvdFw3f",
        "outputId": "84f61915-c19e-4aad-ff62-a8d873a9edaa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Classifier - Training Data:\n",
            "Accuracy: 0.8764\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.17      0.28       724\n",
            "           1       0.88      1.00      0.93      4276\n",
            "\n",
            "    accuracy                           0.88      5000\n",
            "   macro avg       0.88      0.58      0.61      5000\n",
            "weighted avg       0.88      0.88      0.84      5000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 6: Implementation using Clustering"
      ],
      "metadata": {
        "id": "F9f86wYnFyuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of clusters\n",
        "n_clusters = 2\n",
        "\n",
        "# Without PCA\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "kmeans.fit(X_train_tfidf)  # Assuming X_train_tfidf is your TF-IDF feature matrix\n",
        "\n",
        "# Make predictions on test data\n",
        "test_predictions = kmeans.predict(X_test_tfidf)\n",
        "\n",
        "# A helper function to help labeling the test predictions\n",
        "def label(n_clusters, real_labels, labels):\n",
        "    permutation = []\n",
        "    for i in range(n_clusters):\n",
        "        idx = labels == i\n",
        "        new_label = scipy.stats.mode(real_labels[idx])[0]  # Choose the most common label among data points in the cluster\n",
        "        permutation.append(new_label)\n",
        "    return permutation\n",
        "\n",
        "# Use the label function to map cluster labels to binary labels (0 or 1)\n",
        "cluster_labels = label(n_clusters, y_test, test_predictions)\n",
        "\n",
        "# Print cluster labels\n",
        "print(\"Cluster Labels without PCA:\", cluster_labels)\n",
        "\n",
        "# With PCA (assuming X_train_pca and X_test_pca are PCA-transformed data)\n",
        "kmeans_pca = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "kmeans_pca.fit(X_train_pca)  # Assuming X_train_pca is PCA-transformed training data\n",
        "\n",
        "# Make predictions on PCA-transformed test data\n",
        "test_predictions_pca = kmeans_pca.predict(X_test_pca)\n",
        "\n",
        "# Use the label function to map cluster labels to binary labels (0 or 1)\n",
        "cluster_labels_pca = label(n_clusters, y_test, test_predictions_pca)\n",
        "\n",
        "# Print cluster labels with PCA\n",
        "print(\"Cluster Labels with PCA:\", cluster_labels_pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwaC_CPkFzv1",
        "outputId": "3cf30cb8-fd07-4fd3-dd71-1f136b428417"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Labels without PCA: [1, 1]\n",
            "Cluster Labels with PCA: [1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on PCA-transformed train data\n",
        "train_predictions_pca = kmeans_pca.predict(X_test_pca)\n",
        "\n",
        "# Use the label function to map cluster labels to binary labels (0 or 1)\n",
        "cluster_labels_pca_train = label(n_clusters, y_test, train_predictions_pca)\n",
        "\n",
        "# Print cluster labels with PCA - Train data\n",
        "print(\"Cluster Labels with PCA:\", cluster_labels_pca_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6xMgrx7F2Rc",
        "outputId": "f2efc700-de3f-4e70-8921-de9ddc0e022c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Labels with PCA: [1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing my sentence using best trained model.\n",
        "- Ensemble classifier based on precion and recall"
      ],
      "metadata": {
        "id": "H1wWUVAtF85P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_label(predicted_sentiment):\n",
        "    if predicted_sentiment[0] == 0:\n",
        "        return \"Negative sentiment\"\n",
        "    else:\n",
        "        return \"Positive sentiment\"\n",
        "\n",
        "# Input your own sentence\n",
        "positive_sentence = \"This product exceeded my expectations. I love it!\"\n",
        "\n",
        "# Vectorize your sentence using the same TF-IDF vectorizer\n",
        "positive_sentence_tfidf = tfidf_vectorizer.transform([positive_sentence])\n",
        "positive_sentence_pca = pca.transform(positive_sentence_tfidf.toarray())\n",
        "positive_sentence_pca_scaled = scaler.transform(positive_sentence_pca)\n",
        "\n",
        "# Predict the sentiment of your sentence using the best trained model\n",
        "predicted_sentiment = sentiment_label(ensemble_classifier.predict(positive_sentence_pca_scaled))\n",
        "print(f\"{positive_sentence} --> {predicted_sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6DacMS5GOJD",
        "outputId": "8118452f-72ef-4bf0-f6e6-50c7a7b46114"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This product exceeded my expectations. I love it! --> Positive sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input your own sentence\n",
        "negative_sentence = \"This product is an absolute disaster. It's a complete waste of money, and I regret buying it. I wouldn't wish this on my worst enemy.\"\n",
        "\n",
        "# Vectorize your sentence using the same TF-IDF vectorizer\n",
        "negative_sentence_tfidf = tfidf_vectorizer.transform([negative_sentence])\n",
        "negative_sentence_pca = pca.transform(negative_sentence_tfidf.toarray())\n",
        "negative_sentence_scaled = scaler.transform(negative_sentence_pca)\n",
        "\n",
        "# Predict the sentiment of your sentence using the best trained model\n",
        "predicted_sentiment = sentiment_label(ensemble_classifier.predict(negative_sentence_scaled))\n",
        "print(f\"{negative_sentence} --> {predicted_sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dFvSDaDGTzk",
        "outputId": "acb4ce8a-2ef6-4057-abcf-8f66c364286f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This product is an absolute disaster. It's a complete waste of money, and I regret buying it. I wouldn't wish this on my worst enemy. --> Positive sentiment\n"
          ]
        }
      ]
    }
  ]
}